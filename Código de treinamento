# train_classifier.py

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, models, datasets
import os
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import time
from PIL import Image 

# ðŸŒŸ NOVOS IMPORTS NECESSÃRIOS PARA GERAR O GRÃFICO ðŸŒŸ
import matplotlib.pyplot as plt
import seaborn as sns 

# ==============================================================================
# 1. PRÃ‰-PROCESSAMENTO DOS DADOS (Etapa 3.3)
# ==============================================================================

# DefiniÃ§Ã£o dos parÃ¢metros do projeto
# ATENÃ‡ÃƒO: Verifique a letra da sua unidade (G:) e o caminho.
PROJECT_ROOT = r'C:\pytorch_luva_projeto'
DATA_DIR = os.path.join(PROJECT_ROOT, 'data') 
NUM_CLASSES = 2 
IMAGE_SIZE = 224 # Tamanho esperado pela ResNet
BATCH_SIZE = 8
NUM_EPOCHS = 20 # Reduzido para testar o pipeline rapidamente
LEARNING_RATE = 0.001

# ConfiguraÃ§Ã£o do dispositivo (GPU ou CPU)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

print(f"Dispositivo de execuÃ§Ã£o: {device}")

# 1.1. TransformaÃ§Ãµes de Imagem (Data Augmentation e NormalizaÃ§Ã£o)
train_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(IMAGE_SIZE),
    transforms.RandomRotation(15), 
    transforms.RandomHorizontalFlip(), 
    transforms.ColorJitter(brightness=0.1, contrast=0.1), 
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) 
])

# TransformaÃ§Ãµes para ValidaÃ§Ã£o e Teste (sem Data Augmentation)
val_test_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(IMAGE_SIZE),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 1.2. Carregamento dos Dados
try:
    image_datasets = {
        x: datasets.ImageFolder(os.path.join(DATA_DIR, x), 
                                 train_transforms if x == 'train' else val_test_transforms)
        for x in ['train', 'val', 'test']
    }

    dataloaders = {
        x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=0) # num_workers=0 para Windows e evitar erros
        for x in ['train', 'val', 'test']
    }
    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}
    class_names = image_datasets['train'].classes # Deve ser ['com_defeito', 'sem_defeito']

    print(f"Classes: {class_names}")
    print(f"Tamanhos dos datasets: Treinamento={dataset_sizes['train']}, ValidaÃ§Ã£o={dataset_sizes['val']}, Teste={dataset_sizes['test']}")

except Exception as e:
    print(f"\n[ERRO FATAL] Falha ao carregar os dados. Verifique o caminho DATA_DIR e a estrutura de pastas:\n{e}")
    exit()

# ==============================================================================
# 2. MÃ“DULO DE PLOTAGEM DA MATRIZ DE CONFUSÃƒO (NOVA FUNÃ‡ÃƒO)
# ==============================================================================

def plot_confusion_matrix(cm, class_names):
    """
    FunÃ§Ã£o para plotar a Matriz de ConfusÃ£o como um mapa de calor.
    cm: Matriz de ConfusÃ£o (array numpy)
    class_names: Lista de nomes das classes (ex: ['com_defeito', 'sem_defeito'])
    """
    plt.figure(figsize=(8, 6))
    sns.heatmap(
        cm, 
        annot=True,              # Mostrar os nÃºmeros em cada cÃ©lula
        fmt='d',                 # Formato para nÃºmeros inteiros (contagens)
        cmap='Blues',            # Esquema de cores
        xticklabels=class_names, # RÃ³tulos do eixo X (Previsto)
        yticklabels=class_names, # RÃ³tulos do eixo Y (Verdadeiro)
        cbar=True                # Mostrar barra de cores
    )
    plt.title('Matriz de ConfusÃ£o do Modelo (Conjunto de Teste)')
    plt.ylabel('RÃ³tulo Verdadeiro')
    plt.xlabel('RÃ³tulo Previsto')
    
    # Salva o grÃ¡fico como imagem para o artigo
    plt.savefig('confusion_matrix_heatmap.png') 
    plt.show() # Exibe o grÃ¡fico


# ==============================================================================
# 3. DESENVOLVIMENTO DO MODELO (Etapa 3.4 - TransferÃªncia de Aprendizado)
# ==============================================================================

def setup_model():
    """
    Configura a Rede Neural Convolucional (CNN) ResNet18.
    """
    model_ft = models.resnet18(weights='IMAGENET1K_V1')
    
    # Congela os pesos de todas as camadas
    for param in model_ft.parameters():
        param.requires_grad = False

    # Substitui a Ãºltima camada para 2 classes
    num_ftrs = model_ft.fc.in_features
    model_ft.fc = nn.Linear(num_ftrs, NUM_CLASSES) 

    model_ft = model_ft.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer_ft = optim.Adam(model_ft.fc.parameters(), lr=LEARNING_RATE) 
    
    return model_ft, criterion, optimizer_ft

model, criterion, optimizer = setup_model()


# ==============================================================================
# 4. TREINAMENTO E VALIDAÃ‡ÃƒO (Etapa 3.5)
# ==============================================================================

def train_and_validate_model(model, criterion, optimizer, num_epochs):
    """
    Realiza o treinamento e a validaÃ§Ã£o, salvando o melhor modelo.
    """
    since = time.time()
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch+1}/{num_epochs}')
        print('-' * 20)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train() 
            else:
                model.eval() 

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # Salva o melhor modelo
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                torch.save(model.state_dict(), 'best_luva_classifier.pth')
                print(">>> Melhor modelo salvo! <<<")

    time_elapsed = time.time() - since
    print(f'\nTreinamento concluÃ­do em {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Melhor AcurÃ¡cia de ValidaÃ§Ã£o: {best_acc:.4f}')
    return model

# ==============================================================================
# 5. AVALIAÃ‡ÃƒO DE DESEMPENHO (Etapa 3.6) - COM PLOTAGEM DA MATRIZ
# ==============================================================================

def evaluate_model(model, criterion):
    """
    Calcula as mÃ©tricas de desempenho no conjunto de TESTE e PLOTA a Matriz de ConfusÃ£o.
    """
    model.eval()
    y_true = []
    y_pred = []
    
    test_loss = 0.0
    
    with torch.no_grad():
        for inputs, labels in dataloaders['test']:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            loss = criterion(outputs, labels)

            test_loss += loss.item() * inputs.size(0)

            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    # CÃ¡lculo da Loss e AcurÃ¡cia
    final_loss = test_loss / dataset_sizes['test']
    accuracy = accuracy_score(y_true, y_pred)
    
    # IMPORTANTE: pos_label=0 (se 'com_defeito' for a primeira pasta)
    precision = precision_score(y_true, y_pred, pos_label=0, average='binary', zero_division=0) 
    recall = recall_score(y_true, y_pred, pos_label=0, average='binary', zero_division=0)
    f1 = f1_score(y_true, y_pred, pos_label=0, average='binary', zero_division=0)
    conf_matrix = confusion_matrix(y_true, y_pred)

    print('\n' + '='*50)
    print('AVALIAÃ‡ÃƒO DE DESEMPENHO NO CONJUNTO DE TESTE (Etapa 3.6)')
    print('='*50)
    print(f'Test Loss: {final_loss:.4f}')
    print(f'AcurÃ¡cia: {accuracy:.4f}')
    print(f'PrecisÃ£o: {precision:.4f}')
    print(f'RevocaÃ§Ã£o (Recall): {recall:.4f}')
    print(f'F1-Score: {f1:.4f}')
    print('\nMatriz de ConfusÃ£o (True vs PrediÃ§Ã£o) - Formato NumÃ©rico:')
    print(conf_matrix)
    print('='*50)
    
    # ðŸŒŸ CHAMADA PARA GERAR O GRÃFICO (MAPA DE CALOR) ðŸŒŸ
    plot_confusion_matrix(conf_matrix, class_names)

# ==============================================================================
# 6. IMPLEMENTAÃ‡ÃƒO DO PROTÃ“TIPO (Etapa 3.7) - FUNÃ‡ÃƒO
# ==============================================================================

def run_inference(model, image_path, transform):
    """
    Carrega uma Ãºnica imagem e emite a decisÃ£o de "aprovado" ou "reprovado".
    """
    print('\n' + '='*50)
    print(f'PROTÃ“TIPO EM AÃ‡ÃƒO (Etapa 3.7): Analisando "{os.path.basename(image_path)}"')
    print('='*50)

    # 1. Carregar e Transformar a Imagem
    try:
        image = Image.open(image_path).convert('RGB')
    except FileNotFoundError:
        print(f"[ERRO] Imagem de inferÃªncia nÃ£o encontrada em: {image_path}")
        return

    # Aplica as mesmas transformaÃ§Ãµes de validaÃ§Ã£o/teste
    input_tensor = transform(image)
    input_batch = input_tensor.unsqueeze(0).to(device)

    # 2. Executar a InferÃªncia
    model.eval()
    with torch.no_grad():
        output = model(input_batch)

    # 3. Processar o Resultado
    _, predicted_class_index = torch.max(output, 1)
    prediction = class_names[predicted_class_index.item()]
    
    # ConfianÃ§a (probabilidade)
    probabilities = torch.nn.functional.softmax(output, dim=1)[0]
    confidence = probabilities[predicted_class_index.item()].item()
    
    # 4. Emitir DecisÃ£o
    print(f"PREVISÃƒO DO SISTEMA: {prediction.upper()}")
    print(f"CONFIANÃ‡A: {confidence:.4f}")
    
    if prediction == 'sem_defeito':
        print("\nDECISÃƒO FINAL: âœ… APROVADA")
    else:
        print("\nDECISÃƒO FINAL: âŒ REPROVADA")
    
    print('='*50)


# ==============================================================================
# 7. EXECUÃ‡ÃƒO PRINCIPAL DO PIPELINE (Fluxo de Controle)
# ==============================================================================
if __name__ == '__main__':
    
    # 1. TREINAMENTO (Etapa 3.5)
    train_and_validate_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS) 

    # 2. CARREGAR O MELHOR MODELO SALVO
    best_model = model
    try:
        best_model.load_state_dict(torch.load('best_luva_classifier.pth'))
        print("\n[SUCESSO] Melhor modelo salvo foi carregado.")
    except FileNotFoundError:
        print("\n[AVISO] Arquivo 'best_luva_classifier.pth' nÃ£o encontrado.")
        print("Usando o modelo treinado na Ãºltima Ã©poca para avaliaÃ§Ã£o e inferÃªncia.")
    
    # 3. AVALIAÃ‡ÃƒO DE DESEMPENHO (Etapa 3.6)
    evaluate_model(best_model, criterion) 

    # 4. PROTÃ“TIPO (Etapa 3.7) - CHAMADA FINAL
    TEST_IMAGE_FILENAME = 'luva_teste.jpg' 
    # Usa o caminho absoluto
    TEST_IMAGE_PATH = os.path.join(PROJECT_ROOT, TEST_IMAGE_FILENAME)
    
    # Verifica se a imagem de teste existe antes de tentar a inferÃªncia
    if os.path.exists(TEST_IMAGE_PATH):
        run_inference(best_model, TEST_IMAGE_PATH, val_test_transforms)
    else:
        print(f"\n[AVISO] O protÃ³tipo (Etapa 3.7) nÃ£o foi executado.")
        print(f"NÃ£o foi possÃ­vel encontrar a imagem em: {TEST_IMAGE_PATH}")
        print(f"Verifique se o caminho PROJECT_ROOT no topo do arquivo estÃ¡ correto.")
